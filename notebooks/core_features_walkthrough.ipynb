{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "236deaeb-877d-415c-bfc1-2c42345a243e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai numpy matplotlib pydantic --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42297da2-2674-4bbb-b8d0-6f230e4fe677",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d81c7c8-e1de-483a-9f64-f94609e80083",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-4.1-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "567b5fa0-010b-449e-96be-2eda419d7a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the client\n",
    "# Note: In a real application, you would use an environment variable or secure method\n",
    "# to store your API key. This is just for demonstration.\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1101d4-5cea-47f0-8240-442bad700a1b",
   "metadata": {},
   "source": [
    "1. Basic Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b47b515e-a116-42dd-8fef-7e93209e1aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Write a one-sentence bedtime story about a unicorn.\n",
      "Response: Under a shimmering moonlit sky, a gentle unicorn sprinkles stardust over a sleepy forest, filling every dream with magic and wonder.\n",
      "\n",
      "With controlled parameters:\n",
      "Response (controlled): Under a silver moon, a gentle unicorn with shimmering wings whispered dreams to the stars, filling the night with magic and peace.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Write a one-sentence bedtime story about a unicorn.\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=prompt\n",
    ")\n",
    "\n",
    "print(f\"Prompt: {prompt}\")\n",
    "print(f\"Response: {response.output_text}\")\n",
    "\n",
    "# Show how to control generation with parameters\n",
    "print(\"\\nWith controlled parameters:\")\n",
    "response = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=prompt,\n",
    "    temperature=0.7,  # Lower for more deterministic outputs\n",
    "    top_p=0.9         # Nucleus sampling\n",
    ")\n",
    "\n",
    "print(f\"Response (controlled): {response.output_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc6c145-5cc0-44d8-a4d5-85b148ea5833",
   "metadata": {},
   "source": [
    "2. Structured Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9eb9b823-bb1c-4634-8759-4bb8756acd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "response = client.responses.create(\n",
    "   model=MODEL,\n",
    "    input=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a UI generator AI. Convert the user input into a UI.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Make a User Profile Form\"}\n",
    "    ],\n",
    "    text={\n",
    "        \"format\": {\n",
    "            \"type\": \"json_schema\",\n",
    "            \"name\": \"ui\",\n",
    "            \"description\": \"Dynamically generated UI\",\n",
    "            \"schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"type\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The type of the UI component\",\n",
    "                        \"enum\": [\"div\", \"button\", \"header\", \"section\", \"field\", \"form\"]\n",
    "                    },\n",
    "                    \"label\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The label of the UI component, used for buttons or form fields\"\n",
    "                    },\n",
    "                    \"children\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"description\": \"Nested UI components\",\n",
    "                        \"items\": {\"$ref\": \"#\"}\n",
    "                    },\n",
    "                    \"attributes\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"description\": \"Arbitrary attributes for the UI component, suitable for any element\",\n",
    "                        \"items\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                              \"name\": {\n",
    "                                  \"type\": \"string\",\n",
    "                                  \"description\": \"The name of the attribute, for example onClick or className\"\n",
    "                              },\n",
    "                              \"value\": {\n",
    "                                  \"type\": \"string\",\n",
    "                                  \"description\": \"The value of the attribute\"\n",
    "                              }\n",
    "                          },\n",
    "                          \"required\": [\"name\", \"value\"],\n",
    "                          \"additionalProperties\": False\n",
    "                      }\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"type\", \"label\", \"children\", \"attributes\"],\n",
    "                \"additionalProperties\": False\n",
    "            },\n",
    "            \"strict\": True,\n",
    "        },\n",
    "    },\n",
    ")\n",
    "\n",
    "ui = json.loads(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f217d871-2196-4e2c-b817-25957767b478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'form',\n",
       " 'label': '',\n",
       " 'children': [{'type': 'section',\n",
       "   'label': 'User Profile Form',\n",
       "   'children': [{'type': 'field',\n",
       "     'label': 'First Name',\n",
       "     'children': [],\n",
       "     'attributes': [{'name': 'type', 'value': 'text'},\n",
       "      {'name': 'name', 'value': 'firstName'},\n",
       "      {'name': 'placeholder', 'value': 'Enter your first name'}]},\n",
       "    {'type': 'field',\n",
       "     'label': 'Last Name',\n",
       "     'children': [],\n",
       "     'attributes': [{'name': 'type', 'value': 'text'},\n",
       "      {'name': 'name', 'value': 'lastName'},\n",
       "      {'name': 'placeholder', 'value': 'Enter your last name'}]},\n",
       "    {'type': 'field',\n",
       "     'label': 'Email',\n",
       "     'children': [],\n",
       "     'attributes': [{'name': 'type', 'value': 'email'},\n",
       "      {'name': 'name', 'value': 'email'},\n",
       "      {'name': 'placeholder', 'value': 'Enter your email'}]},\n",
       "    {'type': 'field',\n",
       "     'label': 'Password',\n",
       "     'children': [],\n",
       "     'attributes': [{'name': 'type', 'value': 'password'},\n",
       "      {'name': 'name', 'value': 'password'},\n",
       "      {'name': 'placeholder', 'value': 'Enter your password'}]},\n",
       "    {'type': 'field',\n",
       "     'label': 'Bio',\n",
       "     'children': [],\n",
       "     'attributes': [{'name': 'type', 'value': 'textarea'},\n",
       "      {'name': 'name', 'value': 'bio'},\n",
       "      {'name': 'placeholder', 'value': 'Tell us about yourself'}]},\n",
       "    {'type': 'button',\n",
       "     'label': 'Submit',\n",
       "     'children': [],\n",
       "     'attributes': [{'name': 'type', 'value': 'submit'}]}],\n",
       "   'attributes': []}],\n",
       " 'attributes': []}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bcbde6-b7ef-4d4a-80d4-81f4ae87bc9c",
   "metadata": {},
   "source": [
    "2.1 Structured Outputs with Pydantic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9bcae9f-5149-43ea-823e-da3227e13909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps=[Step(explanation='Start with the equation: 8x + 7 = -23.', output='8x + 7 = -23'), Step(explanation='Subtract 7 from both sides to isolate the term with x on one side.', output='8x + 7 - 7 = -23 - 7, which simplifies to 8x = -30'), Step(explanation='Divide both sides of the equation by 8 to solve for x.', output='x = -30 / 8'), Step(explanation='Simplify the fraction if possible.', output='x = -15 / 4')] final_answer='x = -15/4'\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class Step(BaseModel):\n",
    "    explanation: str\n",
    "    output: str\n",
    "\n",
    "class MathReasoning(BaseModel):\n",
    "    steps: list[Step]\n",
    "    final_answer: str\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful math tutor. Guide the user through the solution step by step.\"},\n",
    "        {\"role\": \"user\", \"content\": \"how can I solve 8x + 7 = -23\"}\n",
    "    ],\n",
    "    response_format=MathReasoning,\n",
    ")\n",
    "\n",
    "math_reasoning = completion.choices[0].message\n",
    "\n",
    "# If the model refuses to respond, you will get a refusal message\n",
    "if (math_reasoning.refusal):\n",
    "    print(math_reasoning.refusal)\n",
    "else:\n",
    "    print(math_reasoning.parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "653e10fa-9994-4aab-a6e5-8e48649a9c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Step(explanation='Start with the equation: 8x + 7 = -23.', output='8x + 7 = -23')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_reasoning.parsed.steps[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb5eae2-97a0-457f-b615-2f77a9c8a830",
   "metadata": {},
   "source": [
    "3. Multimodal Capabilities - Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1dbd0d0b-6dd3-453b-a151-9a1fee4df97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image features a colorful gradient background. The colors blend smoothly from warm tones like pink, orange, and peach on the top left to cooler tones like blue and light purple on the bottom right. There are no distinct objects or figures in the image; it is an abstract color gradient.\n"
     ]
    }
   ],
   "source": [
    "# For notebook demonstration, we'll use a placeholder URL\n",
    "image_url = \"https://images.unsplash.com/photo-1579546929518-9e396f3cc809?ixlib=rb-4.0.3&ixid=MnwxMjA3fDB8MHxleHBsb3JlLWZlZWR8MXx8fGVufDB8fHx8&w=1000&q=80\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"input_text\", \"text\": \"what's in this image?\"},\n",
    "            {\n",
    "                \"type\": \"input_image\",\n",
    "                \"image_url\": image_url,\n",
    "            },\n",
    "        ],\n",
    "    }],\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc38381-f325-4f40-a05c-9c8af36cabf0",
   "metadata": {},
   "source": [
    "4. Audio Capabilities - Text to Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f49874be-c8e6-4eeb-a5de-899c8239cf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_file_path = \"speech.mp3\"\n",
    "\n",
    "with client.audio.speech.with_streaming_response.create(\n",
    "    model=\"gpt-4o-mini-tts\",\n",
    "    voice=\"coral\",\n",
    "    input=\"Today is a wonderful day to build something people love!\",\n",
    "    instructions=\"Speak in a cheerful and positive tone.\",\n",
    ") as response:\n",
    "    response.stream_to_file(speech_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b696c56-080e-490c-9739-4459450046cf",
   "metadata": {},
   "source": [
    "4.1 Audio Capabilities - Speech to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "903e5b5c-1a7f-476d-9540-fb1ec1bda244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today is a wonderful day to build something people love.\n"
     ]
    }
   ],
   "source": [
    "audio_file= open(\"speech.mp3\", \"rb\")\n",
    "\n",
    "transcription = client.audio.transcriptions.create(\n",
    "    model=\"gpt-4o-transcribe\", \n",
    "    file=audio_file\n",
    ")\n",
    "\n",
    "print(transcription.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25723c66-5f31-4913-a7b6-cccd1268ecc7",
   "metadata": {},
   "source": [
    "5. Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6aa88c90-1d7d-4f68-a686-3c361add12fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_weather(latitude, longitude):\n",
    "    response = requests.get(f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current=temperature_2m,wind_speed_10m&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m\")\n",
    "    data = response.json()\n",
    "    return data['current']['temperature_2m']\n",
    "\n",
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"get_weather\",\n",
    "    \"description\": \"Get current temperature for provided coordinates in celsius.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"latitude\": {\"type\": \"number\"},\n",
    "            \"longitude\": {\"type\": \"number\"}\n",
    "        },\n",
    "        \"required\": [\"latitude\", \"longitude\"],\n",
    "        \"additionalProperties\": False\n",
    "    },\n",
    "    \"strict\": True\n",
    "}]\n",
    "\n",
    "input_messages = [{\"role\": \"user\", \"content\": \"What's the weather like in Paris today?\"}]\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=input_messages,\n",
    "    tools=tools,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7f9a7a5-9821-42f9-b057-cdc88f787a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the tool call and arguments\n",
    "tool_call = response.output[0]\n",
    "args = json.loads(tool_call.arguments)\n",
    "# Call the function\n",
    "result = get_weather(args[\"latitude\"], args[\"longitude\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf60b8e8-f6d9-4aaa-a0cd-6368bdcd1f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current temperature in Paris today is 7.6°C. If you want more detailed weather information, please let me know!\n"
     ]
    }
   ],
   "source": [
    "# Append the tool call and result to the input messages\n",
    "input_messages.append(tool_call) # append model's function call message\n",
    "input_messages.append({ # append result message\n",
    "    \"type\": \"function_call_output\",\n",
    "    \"call_id\": tool_call.call_id,\n",
    "    \"output\": str(result)\n",
    "})\n",
    "\n",
    "response_2 = client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=input_messages,\n",
    "    tools=tools,\n",
    ")\n",
    "print(response_2.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fc99cd-2dbb-42a2-ad65-c470d65b894b",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adae88f3-f801-4101-8855-cf66c8d7f938",
   "metadata": {},
   "outputs": [],
   "source": [
    "6. Reasoning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a977cfd-b9fc-4d78-a29b-eea1917709e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "o3-mini Response:\n",
      "Here’s a step-by-step guide to implementing a basic hash table, covering both separate-chaining and open-addressing strategies, plus essential operations and resizing.\n",
      "\n",
      "1. Core components  \n",
      "   • Array of buckets of fixed length M  \n",
      "   • A hash function h(key) → integer in [0…M–1]  \n",
      "   • Collision-resolution strategy (separate chaining or open addressing)  \n",
      "\n",
      "2. Choice of hash function  \n",
      "   • For strings: polynomial rolling hash, e.g.  \n",
      "     hash = (∑ key[i]·pⁱ) mod M  \n",
      "   • For integers: simple modular reduction, e.g. h(k) = k mod M  \n",
      "\n",
      "3. Strategy A: Separate Chaining  \n",
      "   – Each bucket is a linked list (or dynamic array) of (key, value) pairs.  \n",
      "   – Load factor α = N/M; keep α ≤ 1 or 2 for good performance.\n",
      "\n",
      "   Pseudocode (assume buckets[0…M–1] each is initially empty list):\n",
      "   ```\n",
      "   function insert(key, value):\n",
      "     i = h(key)\n",
      "     for each (k,v) in buckets[i]:\n",
      "       if k == key:\n",
      "         v = value            # update existing\n",
      "         return\n",
      "     buckets[i].append((key,value))\n",
      "\n",
      "   function search(key):\n",
      "     i = h(key)\n",
      "     for (k,v) in buckets[i]:\n",
      "       if k == key:\n",
      "         return v\n",
      "     return NOT_FOUND\n",
      "\n",
      "   function delete(key):\n",
      "     i = h(key)\n",
      "     for idx,(k,v) in enumerate(buckets[i]):\n",
      "       if k == key:\n",
      "         remove buckets[i][idx]\n",
      "         return true\n",
      "     return false\n",
      "   ```\n",
      "\n",
      "4. Strategy B: Open Addressing (Linear Probing)  \n",
      "   – Single array table[0…M–1] holding entries or “EMPTY”/“DELETED” markers.  \n",
      "   – Probe sequence: (h(key) + j) mod M, j = 0,1,2…\n",
      "\n",
      "   Pseudocode:\n",
      "   ```\n",
      "   function insert(key,value):\n",
      "     for j in 0…M–1:\n",
      "       i = (h(key)+j) mod M\n",
      "       if table[i] is EMPTY or DELETED:\n",
      "         table[i] = (key,value); return\n",
      "       if table[i].key == key:\n",
      "         table[i].value = value; return\n",
      "     raise “HashTable Full”\n",
      "\n",
      "   function search(key):\n",
      "     for j in 0…M–1:\n",
      "       i = (h(key)+j) mod M\n",
      "       if table[i] is EMPTY:\n",
      "         return NOT_FOUND    # no further keys\n",
      "       if table[i].key == key:\n",
      "         return table[i].value\n",
      "     return NOT_FOUND\n",
      "\n",
      "   function delete(key):\n",
      "     for j in 0…M–1:\n",
      "       i = (h(key)+j) mod M\n",
      "       if table[i] is EMPTY:\n",
      "         return false\n",
      "       if table[i].key == key:\n",
      "         table[i] = DELETED; return true\n",
      "     return false\n",
      "   ```\n",
      "\n",
      "5. Resizing (Rehashing)  \n",
      "   • When load factor α exceeds threshold (e.g. 0.7):  \n",
      "     – Allocate new array of size M′ (often 2×M)  \n",
      "     – Re-insert every existing (key,value) into new table using new M′ and hash function  \n",
      "   • Keeps operations amortized O(1).\n",
      "\n",
      "6. Time & Space Complexity  \n",
      "   • Average-case insert/search/delete: O(1)  \n",
      "   • Worst case (all collisions): O(N) for chaining (degenerates to list), O(M) for open addressing  \n",
      "   • Space: O(M + N) for chaining, O(M) for open addressing  \n",
      "\n",
      "7. Implementation tips  \n",
      "   • Pick M as a prime to reduce clustering (for modular hash)  \n",
      "   • For open addressing, prefer lower load factors (α ≤ 0.5)  \n",
      "   • Implement DELETED markers carefully to avoid breaking probe chains  \n",
      "   • In practice, use built-in libraries unless you need custom behavior  \n",
      "\n",
      "That’s the essence of a hash table. You choose a collision policy, implement the three core operations (insert, search, delete), and add resizing logic to maintain performance.\n"
     ]
    }
   ],
   "source": [
    "# response_o1 = client.responses.create(\n",
    "#     model=\"o1\",\n",
    "#     input=\"Design an algorithm to find the shortest path in a graph.\"\n",
    "# )\n",
    "\n",
    "# print(\"o1 Response:\")\n",
    "# print(response_o1.output_text)\n",
    "\n",
    "# Using o4-mini for faster reasoning\n",
    "response_o4 = client.responses.create(\n",
    "    model=\"o4-mini\",\n",
    "    input=\"Explain how to implement a hash table.\"\n",
    ")\n",
    "\n",
    "print(\"\\no3-mini Response:\")\n",
    "print(response_o4.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfa01c62-ca57-4751-8732-3766c9543834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the reasoning configuration for o4-mini: Reasoning(effort='medium', generate_summary=None, summary=None)\n"
     ]
    }
   ],
   "source": [
    "## With reasoning models, you can view the reasoning process and the steps taken to arrive at the answer.\n",
    "print(\"This is the reasoning configuration for o4-mini:\", response_o4.reasoning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c700e0-26a2-40b6-bb43-ac1e1130ae0c",
   "metadata": {},
   "source": [
    "7. Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d872cdd2-70c3-46df-8ece-1406ce290d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 3072\n",
      "Number of embeddings: 10\n",
      "\n",
      "Similarity Matrix (Dot Products):\n",
      "          king     queen    man      woman    apple    banana   orange   pear     castle   throne  \n",
      "king       1.0000   0.5552   0.4183   0.2938   0.3243   0.3305   0.2879   0.2802   0.3615   0.4027  \n",
      "queen      0.5552   1.0000   0.3073   0.4133   0.3146   0.3191   0.2983   0.2995   0.2969   0.3353  \n",
      "man        0.4183   0.3073   1.0000   0.5713   0.3098   0.3495   0.2973   0.2695   0.2998   0.2650  \n",
      "woman      0.2938   0.4133   0.5713   1.0000   0.3199   0.2937   0.2784   0.2533   0.2449   0.2491  \n",
      "apple      0.3243   0.3146   0.3098   0.3199   1.0000   0.4619   0.4588   0.4392   0.3002   0.2340  \n",
      "banana     0.3305   0.3191   0.3495   0.2937   0.4619   1.0000   0.4579   0.3636   0.2777   0.2075  \n",
      "orange     0.2879   0.2983   0.2973   0.2784   0.4588   0.4579   1.0000   0.3822   0.2848   0.2174  \n",
      "pear       0.2802   0.2995   0.2695   0.2533   0.4392   0.3636   0.3822   1.0000   0.2788   0.1929  \n",
      "castle     0.3615   0.2969   0.2998   0.2449   0.3002   0.2777   0.2848   0.2788   1.0000   0.3888  \n",
      "throne     0.4027   0.3353   0.2650   0.2491   0.2340   0.2075   0.2174   0.1929   0.3888   1.0000  \n",
      "\n",
      "Specific relationships:\n",
      "Similarity between 'king' and 'queen': 0.5552\n",
      "Similarity between 'apple' and 'banana': 0.4619\n",
      "Similarity between 'king' and 'apple': 0.3243\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# First, let's create embeddings for a set of words\n",
    "words = [\n",
    "    \"king\", \"queen\", \"man\", \"woman\", \n",
    "    \"apple\", \"banana\", \"orange\", \"pear\",\n",
    "    \"castle\", \"throne\"\n",
    "]\n",
    "\n",
    "# Get embeddings for all words\n",
    "response = client.embeddings.create(\n",
    "    model=\"text-embedding-3-large\",\n",
    "    input=words,\n",
    "    encoding_format=\"float\"\n",
    ")\n",
    "\n",
    "# Extract the embeddings\n",
    "embeddings = [data.embedding for data in response.data]\n",
    "\n",
    "print(f\"Embedding dimension: {len(embeddings[0])}\")\n",
    "print(f\"Number of embeddings: {len(embeddings)}\")\n",
    "\n",
    "# Function to compute dot product between two vectors\n",
    "def dot_product(vec1, vec2):\n",
    "    return np.dot(vec1, vec2)\n",
    "\n",
    "# Compute similarity matrix (dot products between all pairs)\n",
    "similarity_matrix = np.zeros((len(words), len(words)))\n",
    "for i in range(len(words)):\n",
    "    for j in range(len(words)):\n",
    "        similarity_matrix[i][j] = dot_product(embeddings[i], embeddings[j])\n",
    "\n",
    "# Print similarity matrix with labels\n",
    "print(\"\\nSimilarity Matrix (Dot Products):\")\n",
    "print(\"          \" + \" \".join(f\"{word:<8}\" for word in words))\n",
    "for i, word in enumerate(words):\n",
    "    row_values = \" \".join(f\"{similarity_matrix[i][j]:.4f}  \" for j in range(len(words)))\n",
    "    print(f\"{word:<10} {row_values}\")\n",
    "\n",
    "# Check specific relationships\n",
    "king_queen_similarity = dot_product(embeddings[0], embeddings[1])\n",
    "apple_banana_similarity = dot_product(embeddings[4], embeddings[5])\n",
    "\n",
    "print(\"\\nSpecific relationships:\")\n",
    "print(f\"Similarity between 'king' and 'queen': {king_queen_similarity:.4f}\")\n",
    "print(f\"Similarity between 'apple' and 'banana': {apple_banana_similarity:.4f}\")\n",
    "print(f\"Similarity between 'king' and 'apple': {dot_product(embeddings[0], embeddings[4]):.4f}\")\n",
    "\n",
    "# We expect king/queen to be closer to each other than king/apple\n",
    "# And apple/banana to be closer to each other than queen/banana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28867cce-b1e9-45ad-846d-1e6e9a0b1383",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ai-prompt-bootcamp)",
   "language": "python",
   "name": "ai-prompt-bootcamp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
